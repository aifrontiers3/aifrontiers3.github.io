<!-- archive--><!DOCTYPE html><html prefix="og: http://ogp.me/ns#"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title>AI Frontiers Conference</title><meta property="og:title" content="AI Frontiers Conference"><meta property="og:image" content="//www.aifrontiers.com/images/ogp-image.png"><meta property="og:description" content="AI Frontiers is a premier Applied AI Conference that brings together AI leaders and practitioners to share the cutting edge solutions and latest advances in deep learning product."><meta property="og:url" content="//www.aifrontiers.com"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/images/favicon.png"><link rel="stylesheet" href="/vendor/slickNav/slicknav.css"><link rel="stylesheet" href="/vendor/slick/slick.css"><link rel="stylesheet" href="/vendor/jquery-modal/jquery.modal.css" type="text/css" media="screen"><link rel="stylesheet" href="/css/main.css"><!-- Google Tag Manager--><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-K869LBB');</script><!-- End Google Tag Manager--><link rel="search" type="application/opensearchdescription+xml" href="http://aifrontiers.com/atom.xml" title="AI Frontiers Conference"><!-- Global site tag (gtag.js) - Google AdWords: 830904628--><script async src="https://www.googletagmanager.com/gtag/js?id=AW-830904628"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'AW-830904628');</script></head><body class="archive"><!-- Google Tag Manager (noscript)--><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-K869LBB" height="0" width="0" style="display:none;visibility:hidden;"></iframe></noscript><!-- End Google Tag Manager (noscript)--><div class="wrap"><header><div class="header-wrap"><div class="logo-group"><a class="logo-link site-track" href="/"><img src="/images/logo-horizontal.png" alt="logo"></a><span class="conf-date">November 9-11, 2018</span></div><div class="header-right"><div class="navigation"><ul class="nav nav-main nav-list"><li class="nav-list-item"><a class="nav-list-link" href="/#topics" target="_self">Topics</a></li><li class="nav-list-item"><a class="nav-list-link" href="/#speakers" target="_self">Speakers</a></li><li class="nav-list-item"></li><li class="nav-list-item"><a class="nav-list-link" href="/#spnrs" target="_self">Sponsors</a></li><li class="nav-list-item"><a class="nav-list-link" href="/#venue" target="_self">Venue</a></li></ul><ul class="nav nav-sub nav-list"><li class="nav-list-item"><a class="nav-list-link" href="http://jan2017.aifrontiers.com/" onclick="trackOutboundLink('http://jan2017.aifrontiers.com/')" target="_blank">Jan 2017 Conference</a></li><li class="nav-list-item"><a class="nav-list-link" href="http://nov2017.aifrontiers.com/" onclick="trackOutboundLink('http://nov2017.aifrontiers.com/')" target="_blank">Nov 2017 Conference</a></li><li class="nav-list-item"><a class="nav-list-link" href="/about" target="_self">About Us</a></li><li class="nav-list-item"><a class="nav-list-link" href="/#contact" target="_self">Contact Us</a></li></ul><ul class="nav nav-mobile nav-list" style="display:none;"><div class="main-items"><li class="nav-list-item main-nav-list-item"><a class="nav-list-link" href="/#topics" target="_self">Topics</a></li><li class="nav-list-item main-nav-list-item"><a class="nav-list-link" href="/#speakers" target="_self">Speakers</a></li><li class="nav-list-item main-nav-list-item"></li><li class="nav-list-item main-nav-list-item"><a class="nav-list-link" href="/#spnrs" target="_self">Sponsors</a></li><li class="nav-list-item main-nav-list-item"><a class="nav-list-link" href="/#venue" target="_self">Venue</a></li></div><div class="sub-items"><li class="nav-list-item sub-nav-list-item"><a class="nav-list-link" href="http://jan2017.aifrontiers.com/" onclick="trackOutboundLink('http://jan2017.aifrontiers.com/')" target="_blank">Jan 2017 Conference</a></li><li class="nav-list-item sub-nav-list-item"><a class="nav-list-link" href="http://nov2017.aifrontiers.com/" onclick="trackOutboundLink('http://nov2017.aifrontiers.com/')" target="_blank">Nov 2017 Conference</a></li><li class="nav-list-item sub-nav-list-item"><a class="nav-list-link" href="/about" target="_self">About Us</a></li><li class="nav-list-item sub-nav-list-item"><a class="nav-list-link" href="/#contact" target="_self">Contact Us</a></li></div></ul></div><div class="social-bar"><a href="https://www.facebook.com/aifrontiersconference/" alt="facebook"><img class="social-icons" src="/images/socials/facebook.png"></a><a href="https://twitter.com/AI_Frontiers" alt="Twitter"><img class="social-icons" src="/images/socials/twitter.png"></a><a href="https://www.linkedin.com/company/17898981" alt="LinkedIn"><img class="social-icons" src="/images/socials/linkedin.png"></a><a href="https://www.youtube.com/channel/UCdWI86GsaU1Bp1kRkm1UQ1Q" alt="Youtube"><img class="social-icons" src="/images/socials/youtube.png"></a></div><a class="button buy-tickets site-track" href="/register">Register</a></div></div></header><div class="jumbotron"><div id="fgPlayer" style="display: none;"></div><div class="jumbotron-fg"><!-- img.conf-logo(src="/images/logo-horizontal-white.png")--><span class="conf-title"><span class="conf-name">AI Frontiers</span><span class="conf-nd">Conference</span></span><span class="conf-theme"></span><span class="conf-info"><span class="conf-date">November 9-11, 2018</span><span class="sep">, </span><span class="conf-location">San Jose Convention Center</span></span><div class="buttons"><a class="button register-button site-track" href="/register" alt="Register">Register</a><a class="button video-button desktop" alt="Last Edition Video" rel="modal:open" href="#fgPlayer">Watch Video</a><a class="button video-button mobile" alt="Last Edition Video" href="http://m.youtube.com/watch?v=WiD_uWWfqaw?autoplay=1&amp;playsinline">Watch Video</a></div></div><div class="slider"><div class="slide"><div class="img" style="background-image: url(/images/slides/4.jpg); filter: brightness(0.7);"></div></div></div></div><main class="container"><div class="module module-topics"><a class="module-title" name="topics">Our Topics</a><div class="topics"><div class="topic-card"><div class="topic-image-wrapper"><img class="topic-image" src="/images/topics/robots.jpg"><div class="topic-image-mask"></div><span class="topic-title">Robots</span></div><span class="topic-description">What is the status of robots? How do they become smarter?</span></div><div class="topic-card"><div class="topic-image-wrapper"><img class="topic-image" src="/images/topics/chatbot-and-nlp.jpg"><div class="topic-image-mask"></div><span class="topic-title">Home Assistants</span></div><span class="topic-description">The exciting future of chatbots with deep reinforcement learning</span></div><div class="topic-card"><div class="topic-image-wrapper"><img class="topic-image" src="/images/topics/deep-learning-frameworks.jpg"><div class="topic-image-mask"></div><span class="topic-title">Deep Learning Breakthrough</span></div><span class="topic-description">The major breakthroughs in deep learning algorithm and their implications.</span></div><div class="topic-card"><div class="topic-image-wrapper"><img class="topic-image" src="/images/topics/edge-computing.jpg"><div class="topic-image-mask"></div><span class="topic-title">Edge Computing</span></div><span class="topic-description">How will edge computing impact the industry?</span></div><div class="topic-card"><div class="topic-image-wrapper"><img class="topic-image" src="/images/topics/ai-in-healthcare.jpg"><div class="topic-image-mask"></div><span class="topic-title">AI in Healthcare</span></div><span class="topic-description">A look at the application of machine learning in Healthcare industry.</span></div><div class="topic-card"><div class="topic-image-wrapper"><img class="topic-image" src="/images/topics/ai-in-finance.jpg"><div class="topic-image-mask"></div><span class="topic-title">AI in Finance</span></div><span class="topic-description">The growing presence of machine learning in financing.</span></div></div></div><div class="module module-speakers"><a class="module-title" name="speakers">Speakers From Last Conference</a><div class="speakers"><div class="speaker"><img class="photo" src="/images/speakers/Andrew_Ng.jpg"><span class="name">Andrew Ng</span><span class="position">Founder</span><span class="company">Deeplearning.ai</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/Andrew_Ng.jpg"><span class="name">Andrew Ng</span><span class="position">Founder</span><span class="company">Deeplearning.ai</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">9:00 - 10:00am</span><span class="title">AI is the New Electricity</span><span class="description">Similar to the rise of Electricity starting about 100 years ago, AI today is beginning to transform every major industry. This presentation will discuss how AI can transform your business, share major technology trends and thoughts on where your biggest future opportunities may lie, and describe best practices on incorporating AI, machine learning, and deep learning into your organization. These ideas will also be illustrated with some examples that haven't been presented elsewhere before. </span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">Dr. Andrew Ng is a globally recognized leader in AI (Artificial Intelligence).  He was until recently Chief Scientist at Baidu, where he led the company’s ~1300 person AI Group and was responsible for driving the company's global AI strategy and infrastructure. He was also the founding lead of the Google Brain team. Dr. Ng is also Co-Chairman and Co-founder of Coursera, the world’s leading MOOC (Massive Open Online Courses) platform, and an Adjunct Professor at Stanford University's Computer Science Department.  Dr. Ng has authored or co-authored over 100 research papers in machine learning, robotics and related fields. He holds degrees from Carnegie Mellon University, MIT and the University of California, Berkeley.</span></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/xuedong_huang1.jpg"><span class="name">Xuedong Huang</span><span class="position">Chief Scientist  <br>of Speech & Language</span><span class="company">Microsoft</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/xuedong_huang1.jpg"><span class="name">Xuedong Huang</span><span class="position">Chief Scientist  <br>of Speech & Language</span><span class="company">Microsoft</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">7-9pm</span><span class="title">Lessons Learned in Advancing Conversational Assistants</span><span class="description">Speech and language technologies benefited tremendously from the latest progress in machine learning and knowledge engineering. I will share major lessons learned in advancing modern conversational assistants from Cortana to Customer Support Services.</span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">Dr. Xuedong Huang is a Microsoft Technical Fellow in Microsoft AI and Research. He leads Microsoft's Speech and Language Team. As Microsoft's Chief Speech Scientist, he pioneered to lead the team achieving a historical conversational speech recognition human parity milestone in 2016. In 1993, Huang joined Microsoft to found the company's speech technology group. As the general manager of Microsoft's spoken language efforts for over a decade, he helped to bring speech recognition to the mass market by introducing SAPI to Windows in 1995 and Speech Server to the enterprise call center in 2004. Prior to his current role, he spent five years in Bing as chief architect working to improve search and ads. Before Microsoft, he was on the faculty at Carnegie Mellon University and achieved the best performance of all categories in 1992’s DARPA speech recognition benchmarking.  He received Alan Newell research excellence leadership medal in 1992 and IEEE Best Paper Award in 1993. He is an IEEE & ACM fellow. He was named as the Asian American Engineer of the Year (2011), and one of Wired Magazine's 25 Geniuses Who Are Creating the Future of Business (2016). He holds over 100 patents and published over 100 papers & 2 books.</span></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/Alex_Acero.jpg"><span class="name">Alex Acero</span><span class="position">Sr. Director</span><span class="company">Apple Siri</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/Alex_Acero.jpg"><span class="name">Alex Acero</span><span class="position">Sr. Director</span><span class="company">Apple Siri</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">10:00 - 11:30am</span><span class="title">Deep Learning in Siri</span><span class="description">Siri brought personal assistants to the mainstream after its introduction in 2011 in the iPhone. Deep learning is powering many components in Siri: trigger word detection, large vocabulary recognition, text-to-speech, machine translation, and natural language understanding. In this talk I will show a few examples of how deep learning is used in Siri.</span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">Alex Acero is Senior Director in the Siri team in charge of speech recognition, speech synthesis, and machine translation. Prior to joining Apple, he spent 20 years at Microsoft Research managing teams in speech, computer vision, NLP, machine translation, machine learning, and information retrieval. Dr. Acero is an IEEE Fellow and ISCA Fellow. He has served as President of the IEEE Signal Processing Society and is currently a member of the IEEE Board of Directors. He is a co-author of the textbook Spoken Language Processing. Dr. Acero has published over 250 technical papers and has over 150 US patents. He received his Ph.D. from Carnegie Mellon in 1990.</span></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/Ruhi-Sarikaya.jpg"><span class="name">Ruhi Sarikaya</span><span class="position">Director</span><span class="company">Amazon Alexa</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/Ruhi-Sarikaya.jpg"><span class="name">Ruhi Sarikaya</span><span class="position">Director</span><span class="company">Amazon Alexa</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">10:00 - 11:30am</span><span class="title">Natural Language Interaction Challenges for Intelligent Personal Assistants</span><span class="description">There are three fundamental challenges in interacting with the applications and services running behind intelligent personal assistants (IPAs): 1) application/service discovery, 2) learning what these applications can do, and 3) limited information flow into the apps/services. This same challanges manifests itself in all AI enabled systems. For example, users do not know what skills/apps exists that can handle their requests and they also do not know how to interact with those skills/apps in a natural way. Additionally, these systems have limited ability for contextual conversational understanding. We discuss these issues and explain what is needed to truly understand the user’s intent and serve the most relevant answer for the user’s request.</span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">Ruhi Sarikaya joined Amazon Alexa team as the Director of Applied Science in 2016. With his team that he has largely built from the ground up, he has been building core capabilities around ranking, relevance, natural language understanding, dialog management, contextual understanding and personalization. Prior to that, he was a principal science manager and the founder of the language understanding and dialog systems group at Microsoft, Redmond, WA between 2011 and 2016. His group has built language understanding and dialog management capabilities of Cortana, Xbox One and the underlying platform supporting both 1st and 3rd parties. Before Microsoft, he was a research staff member and team lead in the Human Language Technologies Group at IBM T.J. Watson Research Center, Yorktown Height, NY for ten years. Before IBM, he worked as a researcher at the Center for Spoken Language Research (CSLR) at the University of Colorado at Boulder for two years.  Ruhi received his PhD in Electrical and Computer Engineering from Duke University, his MS in Electrical and Computer Engineering from Clemson University, and his BS in Electrical Engineering from Bilkent University.  He has published over 100 technical papers in refereed journal and conference proceedings, and is inventor of over 70 issued/pending patents.</span></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/raul-sukthankar.jpg"><span class="name">Rahul Sukthankar</span><span class="position">Head of Video Understanding</span><span class="company">Google</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/raul-sukthankar.jpg"><span class="name">Rahul Sukthankar</span><span class="position">Head of Video Understanding</span><span class="company">Google</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">1:30-3:00pm</span><span class="title">Large-Scale Video Understanding: YouTube and Beyond</span><span class="description">This talk will present some recent advances in video understanding at Google. It will cover the technology behind progress in applications such as large-scale video annotation for YouTube, video summarization and Motion Stills, as well as our research in weakly-supervised learning, domain adaptation from YouTube to Google Photos and action recognition. I will also give my perspective on promising directions for future research in video.</span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">Rahul Sukthankar leads exploratory research efforts in computer vision, machine learning and robotics at Google. He is also an adjunct research professor at the Robotics Institute at Carnegie Mellon and courtesy faculty at the University of Central Florida. Dr. Sukthankar was previously a senior principal researcher at Intel Labs, a senior researcher at HP/Compaq Labs and a research scientist at Just Research. He received his Ph.D. in Robotics from Carnegie Mellon in 1997 and his B.S.E. in Computer Science from Princeton in 1991. He has organized several academic conferences and serves as Editor in Chief of the Machine Vision and Applications journal.</span></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/xiaofeng_ren.jpg"><span class="name">Xiaofeng Ren</span><span class="position">Chief Scientist</span><span class="company">Alibaba</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/xiaofeng_ren.jpg"><span class="name">Xiaofeng Ren</span><span class="position">Chief Scientist</span><span class="company">Alibaba</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">1:30-3:00pm</span><span class="title">The Quest for Video Understanding</span><span class="description">In this talk I will briefly discuss the ubiquitous needs of video and video understanding across Alibaba and the challenges that are being addressed and solved at iDST, Alibaba's AI R&D division. Examples include mobile shopping on Taobao, video search and recommendation on Youku and Tudou, and real-time systems for Cainiao Logistics and City Brain.</span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">Xiaofeng Ren is currently chief scientist and deputy dean of the Institute of Data Science and Technologies (iDST) at Alibaba Group. He leads computer vision teams at iDST that work across Alibaba Group's diverse e-commerce businesses, from Taobao and TianMao to Youku, Tudou, Alibaba Cloud, and beyond. For 2013-17, he was a senior principal scientist at Amazon and led algorithm developments of Amazon Go. For 2008-13, he was at Intel Labs Seattle and led computer vision research on RGB-D perception (consumer depth cameras) and wearable cameras. For 2006-08 he was on the research faculty of Toyota Technological Institute at Chicago. He received his Ph.D. from UC Berkeley in 2006. Xiaofeng's research and interests span a range of computer vision topics including local features, boundary detection, optical flow, tracking, object detection and recognition, scene understanding, and activity recognition. He holds an affiliate faculty position at University of Washington.</span></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/Danny_Shapiro.jpg"><span class="name">Danny Shapiro</span><span class="position">Sr. Director of Automotive</span><span class="company">Nvidia</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/Danny_Shapiro.jpg"><span class="name">Danny Shapiro</span><span class="position">Sr. Director of Automotive</span><span class="company">Nvidia</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">3:40-4:40pm</span><span class="title">Accelerating the Race to AI Self-Driving Cars</span><span class="description">AI is transforming industries from consumer services to robotics. The transportation industry is next. As the industry moves from ADAS to the next-generation of self-driving technology, breakthroughs in computing are changing how we interact with vehicles, and enabling them to drive us. Deep learning is the game-changing technology behind all autonomous vehicle development. This session will showcase some of the latest deep learning systems from the data center to the vehicle being development to create safe and secure self-driving vehicles.</span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">Danny Shapiro is senior director of Automotive at NVIDIA, focusing on artificial intelligence (AI) solutions self-driving cars, trucks and shuttles. The NVIDIA automotive team is engaged with over 225 car and truck makers, tier 1 suppliers, HD mapping companies, sensor companies and startup companies that are all using the company's DRIVE PX hardware and software platform for autonomous vehicle development and deployment. Danny serves on the advisory boards of the Los Angeles Auto Show, the Connected Car Council and the NVIDIA Foundation, which focuses on computational solutions for cancer research. He holds a Bachelor of Science in electrical engineering and computer science from Princeton University and an MBA from the Haas School of Business at UC Berkeley. </span></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/magnus-nordin.jpg"><span class="name">Magnus Nordin</span><span class="position">Technical Director</span><span class="company">Electronic Arts</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/magnus-nordin.jpg"><span class="name">Magnus Nordin</span><span class="position">Technical Director</span><span class="company">Electronic Arts</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">5:10-6:10pm</span><span class="title">Deep Learning for Game Development</span><span class="description">The number of applications of deep neural networks has multiplied in the last couple of years. Neural nets has enabled significant breakthroughs in everything from computer vision, voice generation, voice recognition, translation, and self-driving cars. Neural nets will also be an powerful enabler for future game development. This presentation will give an overview of the potential of neural nets in game development, as well as provide an in depth look at how we can use neural nets combined with reinforcement learning for new types of game AI.</span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">Magnus published his first game in 1983. Since then he has spent 25 years doing computer science and software engineering in a large number of projects and companies. He is currently working with deep learning and AI research in the gaming industry as the Technical Director of SEED, an EA R&D division.</span></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/jeff_schneider.jpg"><span class="name">Jeff Schneider</span><span class="position">Director</span><span class="company">Uber</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/jeff_schneider.jpg"><span class="name">Jeff Schneider</span><span class="position">Director</span><span class="company">Uber</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">3:40-4:40pm</span><span class="title">Self Driving Cars and AI</span><span class="description">Self driving cars have become one of the hottest areas in tech development today and are poised to transform our transportation systems.  They are also one of the most complex technology developments ever undertaken and are simply not possible without extensive machine learning.  In this talk, I will give a brief history of autonomous vehicle progress, and describe how machine learning and artificial intelligence solve various parts of the problem.  I will finish with observations on how self driving cars will disrupt and transform the transportation industry, our cities, and our lives.</span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">Dr. Jeff Schneider is the engineering lead for machine learning at Uber's Advanced Technologies Center.  He is currently on leave from Carnegie Mellon University where he is a research professor in the school of computer science.  He has 20 years experience developing, publishing, and applying machine learning algorithms in government, science, and industry. He has over 100 publications and regularly gives talks and tutorials on the subject.</span></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/manorhar-paluri.jpg"><span class="name">Manohar Paluri</span><span class="position">Manager of <br>Computer Vision</span><span class="company">Facebook</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/manorhar-paluri.jpg"><span class="name">Manohar Paluri</span><span class="position">Manager of <br>Computer Vision</span><span class="company">Facebook</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">1:30-3:00pm</span><span class="title">Understanding Video</span><span class="description">Video is becoming ubiquitous on the web. From the capture and creation to consumption a lot of amazing things are happening. As folks working in AI this poses a new challenge and great opportunity for us. If we can make machines understand video the way humans do then we can unlock a long set of applications. But, to be able to get there we need to solve many challenging problems, some of which are obvious ones that the academic community is solving – Datasets, Action Recognition, Multi-Modal understanding, Temporal aggregation, Modeling appearance and motion, Compression etc. I would like to discuss these direction and also talk about more longer term directions on self-serve content understanding, large label embedding and video summarization and so on.</span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">Manohar Paluri is currently a Research Lead at Facebook AI research and manages the Computer Vision team in the Applied Machine Learning organization. He is passionate about Computer Vision and in the longer term goal of building systems that can perceive the way humans do. Throughout his career he spent considerable time looking at Computer Vision problems in Industry and Academia. He worked at renowned places like Google Research, IBM Watson Research Labs, Stanford Research Institute before helping co found Facebook AI Research directed by Dr. Yann Lecun.  Mr. Paluri spent his formative years at IIIT Hyderabad where he finished his undergraduate studies with Honors in Computer Vision and joined Georgia Tech. to pursue his Ph.D. For over a decade he has been working on various problems related to Computer Vision and in general Perception and has made various contributions through his publications at CVPR, NIPS, ICCV, ECCV, ICLR, KDD, IROS, ACCV etc. He is passionate about building real world systems that are used by billions of people. Some of these systems are running at Facebook and already have tremendous impact on how people communicate using Facebook.</span></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/james-manyika.jpg"><span class="name">James Manyika</span><span class="position">Chairman and Director</span><span class="company">McKinsey Global Institute</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/james-manyika.jpg"><span class="name">James Manyika</span><span class="position">Chairman and Director</span><span class="company">McKinsey Global Institute</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">3:00-3:15pm</span><span class="title">Sizing up the promise of AI</span><span class="description">This presentation will draw on new findings from the McKinsey Global Institute's ongoing research on the economic and business impact of AI. It will explore four key questions for AI today: who is investing and where, who is adopting AI and how, where can AI improve corporate performance, and what do business leaders need to know tomorrow morning.</span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">James Manyika is a senior partner at McKinsey & Company and chair and director of the McKinsey Global Institute (MGI), the firm’s business and economics research arm.</span></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/lukasz-kaiser.jpg"><span class="name">Lukasz Kaiser</span><span class="position">Sr. Research Scientist</span><span class="company">Google Brain</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/lukasz-kaiser.jpg"><span class="name">Lukasz Kaiser</span><span class="position">Sr. Research Scientist</span><span class="company">Google Brain</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">4:40-5:05pm</span><span class="title">One Model to Learn It All</span><span class="description">Deep learning yields great results across many fields, from speech recognition, image classification, to translation. But for each problem, getting a deep model to work well involves research into the architecture and a long period of tuning. We present a single model that yields good results spanning multiple domains. This single model is trained concurrently on ImageNet, multiple translation tasks, image captioning, a speech recognition corpus, and an English parsing task. We achieved state-of-the-art performance while training much quicker and generating long coherent pieces, even on the scale of full Wikipedia articles. Our new architectures improve the ability to generate both text and images.</span></div></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/dilek.jpg"><span class="name">Dilek Hakkani-Tur</span><span class="position">Research Scientist</span><span class="company">Google</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/dilek.jpg"><span class="name">Dilek Hakkani-Tur</span><span class="position">Research Scientist</span><span class="company">Google</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">10:00 - 11:30am</span><span class="title">Conversational machines: Deep Learning for Goal-Oriented Dialogue Systems</span><span class="description">Creating automated agents with human-level intelligence still remains one of the most challenging problems of AI. In this talk, I will present recent developments in Google Research for end-to-end goal-oriented dialogue systems, with components for language understanding, dialogue state tracking, policy, and language generation. These can be independently built and jointly optimized for dialogue quality and efficient task completion using supervised or reinforcement learning methods. The talk will summarize novel aspects of each component, and highlight novel approaches where we view dialogue as a collaborative game between a user and an agent: The user has a goal in mind and the agent has access to the data that user is interested in, and can perform actions in order to realize the user’s goal. The two engage in a conversation so that the agent can learn the user requirements and help the user browse possible alternatives and find a way for task completion. </span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">Dilek Hakkani-Tür is a research scientist at Google. Prior to joining Google, she was a researcher at Microsoft Research(2010-2016), International Computer Science Institute (ICSI, 2006-2010) and AT&T Labs-Research (2001-2005). She received her BSc degree from Middle East Technical Univ, in 1994, and MSc and PhD degrees from Bilkent Univ., Department of Computer Engineering, in 1996 and 2000, respectively. Her research interests include natural language and speech processing, spoken dialogue systems, and machine learning for language processing. She has over 50 patents that were granted and co-authored more than 200 papers in natural language and speech processing. She is the recipient of three best paper awards for her work on active learning for dialogue systems, from IEEE Signal Processing Society, ISCA and EURASIP. She was an associate editor of IEEE Transactions on Audio, Speech and Language Processing (2005-2008), member of the IEEE Speech and Language Technical Committee (2009-2014), area editor for speech and language processing for Elsevier's Digital Signal Processing Journal and IEEE Signal Processing Letters (2011-2013). She is a fellow of IEEE and ISCA.</span></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/yuandong-tian.jpg"><span class="name">Yuandong Tian</span><span class="position">Research Scientist</span><span class="company">Facebook</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/yuandong-tian.jpg"><span class="name">Yuandong Tian</span><span class="position">Research Scientist</span><span class="company">Facebook</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">5:10-6:10pm</span><span class="title">AI in Games: Achievements and Challenges</span><span class="description">Recently, substantial progress of AI has been made in applications that require advanced pattern reading, including computer vision, speech recognition and natural language processing. However, it remains an open problem whether AI will make the same level of progress in tasks that require sophisticated reasoning, planning and decision making in complicated game environments similar to the real-world. In this talk, I present the state-of-the-art approaches to build such an AI, our recent contributions in terms of designing more effective algorithms and building extensive and fast general environments and platforms, as well as issues and challenges.</span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">Yuandong Tian is a Research Scientist in Facebook AI Research, working on deep reinforcement learning in games and theoretical analysis of deep non-convex models. He is the leader researcher and engineer for DarkForest (Facebook Computer Go project). Prior to that, he was a Software Engineer/Researcher in Google Self-driving Car team during 2013-2014. He received Ph.D in Robotics Institute, Carnegie Mellon University on 2013, Bachelor and Master degree of Computer Science in Shanghai Jiao Tong University. He is the recipient of 2013 ICCV Marr Prize Honorable Mentions for his work on global optimal solution to non-convex optimization in image alignment.</span></div></div></div></div><div class="speaker"><img class="photo" src="/images/speakers/kaijen.jpg"><span class="name">Kaijen Hsiao</span><span class="position">CTO</span><span class="company">Mayfield Robotics</span><div class="details"><span class="close-button">⨉</span><div class="wrap"><img class="photo" src="/images/speakers/kaijen.jpg"><span class="name">Kaijen Hsiao</span><span class="position">CTO</span><span class="company">Mayfield Robotics</span><div class="sessions"><div class="session"><span class="day">Day 1</span><span class="time">11:30 - 12:30pm</span><span class="title">Adorable Intelligence</span><span class="description">Join us to hear how we created Kuri, the world’s most adorable home robot, and how cuteness and machine learning algorithms come together in creating a robot that people are excited to bring into their homes.  Kuri uses embedded, deep-learning-based algorithms for face, pet, and person detection, as well as for place recognition (for mapping and localization).  Such algorithms are crucial for enabling her endearing interactions with people, as well as her ability to be the family videographer and entertainer. Cute behaviors also enable Kuri to subtly and smoothly gather necessary data for training and inference, providing a significant benefit in improving core functionality for adorable home robots.</span></div></div><div class="bio"><span class="title">Speaker Bio</span><span class="content">As the CTO of a game-changing, consumer robotics company, I strive to open-up the new capabilities of robotics technology, with particular attention on shared autonomous teleoperation, imitation learning, tactile grasp adjustment, human-aware navigation and, robot mapping and localization. Across my career at MIT, Bosch, and Willow Garage, she has assembled, accelerated, and led robotics teams producing marketable breakthroughs that have sparked startup businesses in the US and Europe. A few more accolades: Robohub honored me as one of the “25 Women in Robotics You Need to Know about,” and I've also been honored as one of Silicon Valley Business Journal's "Women of Influence."</span></div></div></div></div></div><a class="moderator-title"></a><div class="moderators"></div></div><div class="subscribe"><div class="subscribe-wrap"><span class="text">Sign up for news update</span><form id="mc-embedded-subscribe-form" action="//AIFrontiers.us14.list-manage.com/subscribe/post?u=de145912b09007eeae1b898e9&amp;id=c9295d15d9" method="post" name="mc-embedded-subscribe-form" target="_blank" novalidate="novalidate"><input class="required email" id="mce-EMAIL" placeholder="Enter your email" type="email" value="" name="EMAIL"/><div class="clear" id="mce-responses"><div class="response" id="mce-error-response" style="display:none;"></div><div class="response" id="mce-success-response" style="display:none;"></div></div><!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups--><div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_de145912b09007eeae1b898e9_c9295d15d9" tabindex="-1" value=""/></div><input id="mc-embedded-subscribe" type="submit" value="Subscribe" name="subscribe"/></form></div></div><div class="module module-program"><a class="module-title" name="program">Conference Program</a><p class="program-description">In this three-day conference, we bring together leading scientists and practitioners who have deployed large-scale AI products. You will gain a front-row seat of the frontiers of AI and have opportunity to network with others who are enthusiastic about AI technology and products.</p><div class="program"><div class="heading-box"><a class="day-heading">Day 1</a><span class="day-date">November 9, 2018</span></div><div class="session"><div class="session-title"><div class="session-time">9:00-10:00am</div><div class="session-time-mobile">9:00-10:00am</div>Keynote</div><div class="session-description">Overview of the development of deep learning and its applications.</div></div><div class="session"><div class="session-title"><div class="session-time">10:00-11:30am</div><div class="session-time-mobile">10:00-11:30am</div>Personal Assistants</div><div class="session-description">A panel of industry experts and leading scientists on Personal Assistants and natural language processing come together to discuss their work. What's the future of chatbot?</div></div><div class="session"><div class="session-title"><div class="session-time">11:30-12:30pm</div><div class="session-time-mobile">11:30-12:30pm</div>Robots</div><div class="session-description">A panel of industry experts from companies that are actively developing robots come together to discuss their work. What is the status of robots? How do we build smart home robot?</div></div><div class="session dim"><div class="session-time">12:30-1:30pm</div><div class="session-title">Lunch</div><div class="session-description"></div></div><div class="session"><div class="session-title"><div class="session-time">1:30-3:00pm</div><div class="session-time-mobile">1:30-3:00pm</div>Deep Learning Breakthrough</div><div class="session-description">Leading scientists are presenting the current breakthrough in deep learning, ranging from multimodal learning and continuous prediction (generative model).</div></div><div class="session"><div class="session-title"><div class="session-time">3:00-3:15pm</div><div class="session-time-mobile">3:00-3:15pm</div>Industry Talk</div><div class="session-description">McKinsey report on the impact of AI.</div></div><div class="session dim"><div class="session-time">3:15-3:40pm</div><div class="session-title">Coffee Break</div><div class="session-description"></div></div><div class="session"><div class="session-title"><div class="session-time">3:40-4:40pm</div><div class="session-time-mobile">3:40-4:40pm</div>Edge Computing</div><div class="session-description">How will edge computing impact the industry?</div></div><div class="session"><div class="session-title"><div class="session-time">4:40-5:05pm</div><div class="session-time-mobile">4:40-5:05pm</div>AI in Healthcare</div><div class="session-description">A look at the application of machine learning in Healthcare industry.</div></div><div class="session"><div class="session-title"><div class="session-time">5:10-6:10pm</div><div class="session-time-mobile">5:10-6:10pm</div>AI in Finance</div><div class="session-description">The growing presence of machine learning in financing.</div></div><div class="session"><div class="session-title"><div class="session-time">7-9pm</div><div class="session-time-mobile">7-9pm</div>Dinner Banquet</div><div class="session-description">The banquet is a full course sit down dinner with wine, and a chance to interact with the speakers on an one to one basis. It also includes a presentation by a keynote banquet speaker. You will have the opportunity to meet and mingle with other guests, build connections, raise company profile, form potential business and research partnerships.</div></div><div class="heading-box"><a class="day-heading">Day 2</a><span class="day-date">November 10, 2018</span></div><div class="session"><div class="session-title"><div class="session-time">9am-9:30pm</div><div class="session-time-mobile">9am-9:30pm</div></div><div class="session-description">Morning Keynote</div></div><div class="session"><div class="session-title"><div class="session-time">9:30-10:30am</div><div class="session-time-mobile">9:30-10:30am</div>Morning Talks Session 1</div><div class="session-description">Presentations and Demos.<br></div></div><div class="session dim"><div class="session-time">10:30-11:00am</div><div class="session-title">Break</div><div class="session-description"></div></div><div class="session"><div class="session-title"><div class="session-time">11:00-12:30pm</div><div class="session-time-mobile">11:00-12:30pm</div>Morning Talks Session 2</div><div class="session-description">Presentations and Demos</b>.</div></div><div class="session dim"><div class="session-time">12:30-1:30pm</div><div class="session-title">Lunch</div><div class="session-description"></div></div><div class="session"><div class="session-title"><div class="session-time">1:30-3:00pm</div><div class="session-time-mobile">1:30-3:00pm</div>Afternoon Talks</div><div class="session-description">Presentations and Demos from exciting <b>AI startups</b>.<br></div></div><div class="session dim"><div class="session-time">3:00-3:30pm</div><div class="session-title">Break</div><div class="session-description"></div></div><div class="session"><div class="session-title"><div class="session-time">3:30-5:10pm</div><div class="session-time-mobile">3:30-5:10pm</div>Startup Demo Session</div><div class="session-description">Demos from 10 startups, each startup has 5 minutes for the demo and 5-minute comments from the VC panel.</div></div><div class="heading-box"><a class="day-heading">Day 3</a><span class="day-date">November 11, 2018</span></div><div class="session"><div class="session-title"><div class="session-time">8:30am-12:30pm</div><div class="session-time-mobile">8:30am-12:30pm</div></div><div class="session-description"><b>Hands-on Training session 1</b></div></div><div class="session"><div class="session-title"><div class="session-time">1:30pm-5:30pm</div><div class="session-time-mobile">1:30pm-5:30pm</div></div><div class="session-description"><b>Hands-on Training session 2</b></div></div></div></div><div class="module module-spnrs"><a class="module-title" name="spnrs">Sponsors</a><span class="last-years-spnrs">Previous Sponsors</span><div class="spnrs"><a href="https://www.google.com/"><img class="spnr-logo" src="/images/sponsors/google.png" alt="Google" style="height: 40px; top: 0px;"></a><a href="https://www.facebook.com/"><img class="spnr-logo" src="/images/sponsors/facebook.png" alt="Facebook" style="height: 30px; top: 0px;"></a><a href="https://www.crowdflower.com/"><img class="spnr-logo" src="/images/sponsors/crowdflower.png" alt="CrowdFlower" style="height: 40px; top: 0px;"></a><a href="https://c3iot.com/"><img class="spnr-logo" src="/images/sponsors/C3IoT.png" alt="C3IoT" style="height: 50px; top: 0px;"></a><a href="https://www.microsoft.com/"><img class="spnr-logo" src="/images/sponsors/microsoft.png" alt="Microsoft" style="height: 40px; top: 0px;"></a><a href="https://www.myntra.com/"><img class="spnr-logo" src="/images/sponsors/myntra.jpg" alt="Myntra" style="height: 50px; top: 0px;"></a><a href="https://www.jd.com/"><img class="spnr-logo" src="/images/sponsors/jd.png" alt="JD" style="height: 40px; top: 0px;"></a><a href="https://aws.amazon.com/"><img class="spnr-logo" src="/images/sponsors/aws.jpg" alt="AWS" style="height: 35px; top: 8px;"></a><a href="https://www.ibm.com/"><img class="spnr-logo" src="/images/sponsors/ibm.png" alt="IBM" style="height: 40px; top: 0px;"></a><a href="http://www.huawei.com/"><img class="spnr-logo" src="/images/sponsors/huawei.jpg" alt="Huawei" style="height: 40px; top: 0px;"></a><a href="http://www.cloudwalk.cn/"><img class="spnr-logo" src="/images/sponsors/cloudwalk.png" alt="Cloud Walk" style="height: 45px; top: 0px;"></a><a href="https://www.mckinsey.com/"><img class="spnr-logo" src="/images/sponsors/mckinsey.png" alt="McKinsey" style="height: 30px; top: 4px;"></a><a href="https://www.wharton.upenn.edu/"><img class="spnr-logo" src="/images/sponsors/k@w.png" alt="Wharton School" style="height: 20px; top: 4px;"></a></div><a class="button spnrship-letter site-track" href="sponsor-us">Be Our Sponsor</a></div><div class="module module-news"><a class="module-title" name="news">In the News</a><div class="news"><div class="news-card"><div class="news-logo-wrap"><img class="news-logo" src="/images/news/MIT-Technology-Review.png" alt="MIT Technology Review"></div><blockquote class="news-quote"><a href="https://www.technologyreview.com/s/603381/ai-software-learns-to-make-ai-software/">In Article “AI Software learns to make AI Software”: Jeff Dean spoke at AI Frontiers Conference.</a></blockquote></div><div class="news-card"><div class="news-logo-wrap"><img class="news-logo" src="/images/news/MIT-Technology-Review.png" alt="MIT Technology Review"></div><blockquote class="news-quote"><a href="https://www.technologyreview.com/s/603380/alexa-gives-amazon-a-powerful-data-advantage/">In Article “Alexa Gives Amazon a powerful Data Advantage”: Nikko Strom from Amazon spoke at AI Frontiers Conference.</a></blockquote></div><div class="news-card"><div class="news-logo-wrap"><img class="news-logo" src="/images/news/mashable.png" alt="Mashable"></div><blockquote class="news-quote"><a href="http://mashable.com/2017/01/11/inbox-smart-replies-adoption/">“The stat was revealed by Jeff Dean, senior fellow in Google's research group, who was speaking at AI Frontiers Conference.”</a></blockquote></div><div class="news-card"><div class="news-logo-wrap"><img class="news-logo" src="/images/news/VentureBeat.png" alt="VentureBeat"></div><blockquote class="news-quote"><a href="http://venturebeat.com/2017/01/11/google-has-slashed-its-speech-recognition-word-error-by-more-than-30-since-2012/">Speaking at AI Frontiers Conference, Google senior fellow Jeff Dean provided an update on the accuracy of the company’s speech recognition software.</a></blockquote></div><div class="news-card"><div class="news-logo-wrap"><img class="news-logo" src="/images/news/TechCrunch.png" alt="TechCrunch"></div><blockquote class="news-quote"><a href="https://techcrunch.com/2017/01/11/training-self-driving-cars-on-the-streets-of-los-santos-with-gta-v-just-got-easier/">“Simulation is essential if you really want to do a self driving car,” said Zhaoyin Jia, tech lead for Google Self Driving at today’s AI Frontiers Conference.</a></blockquote></div></div></div><div class="module module-venue"><a class="module-title" name="venue" style="visibility: hidden;"></a><div class="wrapper"><div class="map-wrapper"><iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3172.5712095560993!2d-121.89114378472135!3d37.32898344545465!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x808fccb0748b2f73%3A0x1615f1acacf4449a!2sSan+Jose+McEnery+Convention+Center!5e0!3m2!1sen!2s!4v1528869707440" width="600" height="300" frameborder="0" style="border:0;" allowfullscreen></iframe></div><div class="venue"><div class="venue-mask"></div><div class="conf-info"><div class="venue-date"><span class="date-content content">Nov 9-11, 2018</span></div></div><div class="venue-info"><span class="venue-name">San Jose Convention Center</span><span class="venue-address">150 W San Carlos St<br>San Jose, CA 95113</span></div><a class="button register-button site-track" href="/register">Register</a></div></div><div class="hotel"><div class="left"><span class="suggested-hotel">Partner Hotel</span><div class="hotel-name">San Jose Marriott</div><div class="hotel-address"><span class="hotel-address-first-line"></span>301 S Market St, <span class="hotel-address-first-line"></span>San Jose, CA 95113</div></div><div class="right"><a class="button site-track" href="http://bit.ly/aif_marriott">Book Here With Group Rate</a></div></div></div><div class="module module-contact"><div class="contact"><a class="module-title" name="contact">Contact Us</a><form method="POST" action="https://formspree.io/info@aifrontiers.com"><input class="input-name" type="name" name="name" placeholder="Name" value="" required=""><input class="input-email" type="email" name="_replyto" placeholder="Email" value="" required=""><input class="input-subject" type="subject" name="subject" placeholder="Subject" value="" required=""><textarea class="input-message" name="message" rows="5" placeholder="Message" required=""></textarea><input class="submit-button" type="submit"></form><span class="company-address">940 Stewart Dr. Sunnyvale, CA 94085<br><a href="mailto:info@aifrontiers.com">info@aifrontiers.com</a></span></div></div></main><footer><div class="copyright"><div class="social-bar"><a href="https://www.facebook.com/aifrontiersconference/" alt="facebook"><img class="social-icons" src="/images/socials/facebook.png"></a><a href="https://twitter.com/AI_Frontiers" alt="Twitter"><img class="social-icons" src="/images/socials/twitter.png"></a><a href="https://www.linkedin.com/company/17898981" alt="LinkedIn"><img class="social-icons" src="/images/socials/linkedin.png"></a><a href="https://www.youtube.com/channel/UCdWI86GsaU1Bp1kRkm1UQ1Q" alt="Youtube"><img class="social-icons" src="/images/socials/youtube.png"></a></div><p>© 2018 by <a href="http://aifrontiers.com">Impact Deep LLC.</a></p></div></footer></div><script type="text/javascript">window.mobilecheck = function() {
  var check = false;
  (function(a){
      if(/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0,4))) check = true;
    })(navigator.userAgent||navigator.vendor||window.opera);
  return check;
};
</script><!-- Global Site Tag (gtag.js) - Google Analytics--><script async src="https://www.googletagmanager.com/gtag/js?id=UA-88635436-1"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments)};
gtag('js', new Date());
gtag('config', 'UA-88635436-1');
var trackOutboundLink = function(url) {
  console.log("Outbound!");
  ga('send', 'event', 'outbound', 'click', url, {
      'transport': 'beacon',
      'hitCallback': function(){
        console.log("callback");
        document.location = url;
    }
  });
};
</script><script type="text/javascript" src="/vendor/jquery/jquery.min.js"></script><script type="text/javascript" src="/vendor/slickNav/jquery.slicknav.min.js"></script><script type="text/javascript" src="/vendor/jquery-modal/jquery.modal.js"></script><script type="text/javascript" src="/vendor/slick/slick.min.js"></script><script type="text/javascript" src="https://player.vimeo.com/api/player.js"></script><script type="text/javascript">$(document).ready(function(){
    $('.nav-mobile').slicknav({
        label: "",
        appendTo: ".header-wrap"
    });
})
</script><script type="text/javascript">if ($('body').hasClass('index')) {
    var bgPlayer = false;
    var fgPlayer = false;
    var fgPlayerOptions = {
       id: 227828879,
       autoplay: false,
       title: false,
       height: 500,
       loop: false
    };
    var bgPlayerOptions = {
       id: 227859594,
       autoplay: true,
       title: false,
       loop: true
    };
    if (window.mobilecheck()) {
       var fgPlayerOptions = {
           id: 227828879,
           autoplay: false,
           title: false,
           height: 220,
           loop: false
       };
    }
    else {
       if ($("#bgPlayer").length) {
          bgPlayer = new Vimeo.Player('bgPlayer', bgPlayerOptions);
          bgPlayer.setVolume(0);
       }
    }
    $("#fgPlayer").on($.modal.BEFORE_OPEN, function(event, modal) {
       fgPlayer = new Vimeo.Player('fgPlayer', fgPlayerOptions);
       if (bgPlayer) bgPlayer.pause();
    });
    $("#fgPlayer").on($.modal.OPEN, function(event, modal) {
       if (!window.mobilecheck()) {if (fgPlayer) fgPlayer.play()};
    });
    $("#fgPlayer").on($.modal.BEFORE_CLOSE, function(event, modal) {
       if (bgPlayer) bgPlayer.play();
    });
}
</script><script type="text/javascript">_linkedin_data_partner_id = "91636";
</script><script type="text/javascript">(function(){var s = document.getElementsByTagName("script")[0];
var b = document.createElement("script");
b.type = "text/javascript";b.async = true;
b.src = "https://snap.licdn.com/li.lms-analytics/insight.min.js";
s.parentNode.insertBefore(b, s);})();
</script><script type="text/javascript">$(".module-speakers .speakers .speaker, .module-speakers .moderators .speaker").click(function(e) {
    var target = $(e.target);
    if (target.hasClass("close-button")) {
        $details = target.parent();
        $details.css("opacity", "0");
        $details.css("display", "none");
        $(this).css("cursor", "pointer");
    }
    else {
        $details = $(".details", this);
        $details.css("display", "flex");
        $details.css("opacity", "1");
        $(this).css("cursor", "auto");
    }
});
$(document).keyup(function(e) {
    $details = $(".module-speakers .speakers .speaker .details, .module-speakers .moderators .speaker .details");
    if (e.which == 27) {
        $details.css("opacity", "0");
        $details.css("display", "none");
        $details.parent().css("cursor", "pointer");
    }
});
</script><noscript><img height="1" width="1" style="display:none;" alt="" src="https://dc.ads.linkedin.com/collect/?pid=91636&amp;fmt=gif"></noscript><script type="text/javascript">window.mobilecheck = function() {
  var check = false;
  (function(a){
      if(/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0,4))) check = true;
    })(navigator.userAgent||navigator.vendor||window.opera);
  return check;
};

</script><script type="text/javascript">window.getDict = function() {
  var search = location.search.substring(1);
  return search?JSON.parse('{"' + search.replace(/&/g, '","').replace(/=/g,'":"') + '"}',
    function(key, value) { return key===""?value:decodeURIComponent(value) }):{}
}
</script><!-- ========= Register Tracker =========--><script>$(document).ready(function() {
  $(".site-track").attr("href", $(".site-track").attr("href") + /.*(\?.*)/.exec(window.location.href)[1]);
});

</script><!-- ========= Jumbotron Slider =========--><script>$(document).ready(function(){
    $('.slider').slick({
        autoplay: true,
        autoplaySpeed: "4000",
        dots: true,
        prevArrow: '<button type="button" class="slick-prev slick-arrow"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 21 41" enable-background="new 0 0 21 41"><polygon points="20.3,40.8 0,20.5 20.3,0.2 21,0.9 1.3,20.5 21,40.1 "></polygon></svg></button>',
        nextArrow: '<button type="button" class="slick-next slick-arrow"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 21 41" enable-background="new 0 0 21 41"><polygon points="20.3,40.8 0,20.5 20.3,0.2 21,0.9 1.3,20.5 21,40.1 "></polygon></svg></button>'
    });
});

</script><!-- ========= Countdown =========--><!-- script.--><!--     var D = 'nov 09, 2018';--><!--     (function ($) {--><!--       $.fn.countdown = function(options){--><!--         //global variables--><!--         var vars = $.extend({}, $.fn.countdown.defaults, options),--><!--             $counter = $(this),--><!--             t = {day: 0, hour: 0, minute: 0, sec: 0},--><!--             // targetDate = new Date(vars.targetDate).getTime(),--><!--             // secondsLeft;--><!--             targetDate = new Date(D).getTime(),--><!--             secondsLeft;--><!--         //private methods--><!--         methods = {--><!--           setup: function() {--><!--             $.each(t, function(time, value){--><!--               var currentSection = '<ul id="'+time+'"><li>0</li><li>0</li></ul>';--><!--               $counter.append(currentSection);--><!--             });--><!--             if (vars.labels) {--><!--               var labelHtml = '<div class="labels"><ul><li>DAYS</li><li>HRS</li><li>MIN</li><li>SEC</li></ul></div>';--><!--               $counter.append(labelHtml);--><!--             }--><!--           },--><!--           updateTime: function(){--><!--             var currentTime = new Date().getTime(),--><!--                 secondsLeft = (targetDate - currentTime) / 1000,--><!--                 secsIn = {day: 86400, hour: 3600, minute: 60};--><!--             if (secondsLeft < 0) {secondsLeft = 0;}--><!--             $.each(t, function(timePeriod, value){--><!--               t[timePeriod] = parseInt( (secondsLeft / secsIn[timePeriod]), 10);--><!--               if (timePeriod !== 'sec'){--><!--                secondsLeft = secondsLeft % secsIn[timePeriod];--><!--               }--><!--               else {--><!--                 t[timePeriod] = secondsLeft;--><!--               }--><!--             });--><!--           },--><!--           updateCounter: function() {--><!--             $.each(t, function(period, value){--><!--               var section = $counter.find('#'+period).children();--><!--               digit = splitDigits(value);--><!--               section.eq(0).html(digit[0]);--><!--               section.eq(1).html(digit[1]);--><!--             });--><!--             function splitDigits(number) {--><!--               var digits = [];--><!--               digits[0] = Math.floor(number / 10);--><!--               digits[1] = Math.floor(number % 10);--><!--               return digits;--><!--             }--><!--           },--><!--           tick: function () {--><!--             if (secondsLeft < 1) {}--><!--             else {--><!--               methods.updateTime();--><!--               methods.updateCounter();--><!--               setTimeout(function() {methods.tick();}, 1000);--><!--             }--><!--           },--><!--           init: function () {--><!--             methods.setup();--><!--             methods.updateTime();--><!--             methods.updateCounter();--><!--             methods.tick();--><!--           },--><!--         };--><!--         //initiate countdown--><!--         methods.init();--><!--       };--><!--       $.fn.countdown.defaults = {--><!--         targetDate: D,--><!--         labels: true--><!--       };--><!--     }(jQuery));--><!--     // end of countdown plugin--><!--     // dom ready events (would usually be in separate js file)--><!--     $(document).ready(function() {--><!--       // arbitrarially make a new date--><!--       var newDate = new Date();--><!--       newDate.setDate(45);--><!--       $('.counter').countdown({targetDate: newDate});--><!--     });--><!-- Google Code for Remarketing Tag--><!--------------------------------------------------
Remarketing tags may not be associated with personally identifiable information or placed on pages related to sensitive categories. See more information and instructions on how to setup the tag on: http://google.com/ads/remarketingsetup
---------------------------------------------------><script type="text/javascript">var google_tag_params = {
// dynx_itemid: 'REPLACE_WITH_VALUE',
// dynx_itemid2: 'REPLACE_WITH_VALUE',
// dynx_pagetype: 'REPLACE_WITH_VALUE',
// dynx_totalvalue: 'REPLACE_WITH_VALUE',
};</script><script type="text/javascript">/* <![CDATA[ */
var google_conversion_id = 830904628;
var google_custom_params = window.google_tag_params;
var google_remarketing_only = true;
/* ]]> */</script><script type="text/javascript" src="//www.googleadservices.com/pagead/conversion.js"></script><noscript><div style="display:inline;"><img height="1" width="1" style="border-style:none;" alt="" src="//googleads.g.doubleclick.net/pagead/viewthroughconversion/830904628/?guid=ON&amp;script=0"></div></noscript></body></html>